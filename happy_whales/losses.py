# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/losses.ipynb (unless otherwise specified).

__all__ = ['FocalLoss', 'ArcFaceLoss']

# Cell
import torch.nn as nn
import torch
import math

# Cell
class FocalLoss(nn.Module):
    def __init__(self, gamma=0.25, eps=1e-7):
        super().__init__()

        self.gamma = gamma
        self.eps = eps
        self.cross_entropy = nn.CrossEntropyLoss(reduction="none")

    def forward(self, input, target):
        ce_loss = self.cross_entropy(input, target)
        p = torch.exp(-ce_loss)
        loss = (1 - p) ** self.gamma * ce_loss
        return loss.mean()


# Cell
class ArcFaceLoss(nn.Module):
    def __init__(self, s, m, crit, easy_margin, label_smothing_eps=0):
        super().__init__()

        self.easy_margin = easy_margin
        self.label_smothing_eps = label_smothing_eps

        if crit == "focal":
            self.crit = FocalLoss()
        elif crit == "crossentropy":
            self.crit = nn.CrossEntropyLoss()

        if s is None:
            self.s = torch.nn.Parameter(torch.tensor([30.], requires_grad=True, device='cuda'))
        else:
            self.s = s

        self.cos_m = math.cos(m)
        self.sin_m = math.sin(m)
        self.th = math.cos(math.pi - m)
        self.mm = math.sin(math.pi - m) * m

    def forward(self, logits, labels):

        logits = logits.float()
        cosine = logits
        sine = torch.sqrt(1.0 - torch.pow(cosine, 2))
        phi = cosine * self.cos_m - sine * self.sin_m

        if self.easy_margin:
            phi = torch.where(cosine > 0, phi, cosine)
        else:
            phi = torch.where(cosine > self.th, phi, cosine - self.mm)

        # label one hot encoding
        labels2 = torch.zeros_like(cosine)
        labels2.scatter_(1, labels.view(-1, 1).long(), 1)

        if self.label_smothing_eps > 0:
            labels2 = (1 - self.label_smothing_eps) * labels2 + self.label_smothing_eps / self.num_classes

        output = (labels2 * phi) + ((1.0 - labels2) * cosine)
        output *= self.s

        loss = self.crit(output, labels)

        return loss